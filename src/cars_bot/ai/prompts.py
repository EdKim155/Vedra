"""
Optimized prompts for AI processing using OpenAI best practices (2025).

All prompts are designed to:
- Minimize token usage while maintaining clarity
- Use structured outputs with JSON Schema
- Provide clear, unambiguous instructions
- Include few-shot examples where beneficial
- Support Russian language content
- Leverage system/user roles effectively
"""

from typing import Final

# =============================================================================
# CLASSIFICATION PROMPTS
# =============================================================================

CLASSIFY_POST_SYSTEM_PROMPT: Final[str] = """Ğ¢Ñ‹ ÑĞºÑĞ¿ĞµÑ€Ñ‚ Ğ¿Ğ¾ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾ÑÑ‚Ğ¾Ğ² Ğ¸Ğ· Telegram-ĞºĞ°Ğ½Ğ°Ğ»Ğ¾Ğ² Ğ¾ Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğµ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ¾Ğ±Ğ¸Ğ»ĞµĞ¹.

Ğ—ĞĞ”ĞĞ§Ğ: ĞĞ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸, ÑĞ²Ğ»ÑĞµÑ‚ÑÑ Ğ»Ğ¸ Ğ¿Ğ¾ÑÑ‚ ĞŸĞ ĞĞ”ĞĞ®Ğ©Ğ˜Ğœ ĞĞ‘ĞªĞ¯Ğ’Ğ›Ğ•ĞĞ˜Ğ•Ğœ Ğ¾ Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğµ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ¾Ğ±Ğ¸Ğ»Ñ.

ĞšĞ Ğ˜Ğ¢Ğ•Ğ Ğ˜Ğ˜ Ğ¿Ñ€Ğ¾Ğ´Ğ°ÑÑ‰ĞµĞ³Ğ¾ Ğ¿Ğ¾ÑÑ‚Ğ° (Ğ²ÑĞµ Ğ¸Ğ»Ğ¸ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğ½ÑÑ‚Ğ²Ğ¾ Ğ´Ğ¾Ğ»Ğ¶Ğ½Ñ‹ Ğ¿Ñ€Ğ¸ÑÑƒÑ‚ÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ñ‚ÑŒ):
âœ“ Ğ˜Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾Ğ± Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ¾Ğ±Ğ¸Ğ»Ğµ (Ğ¼Ğ°Ñ€ĞºĞ°, Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ, Ğ³Ğ¾Ğ´)
âœ“ Ğ¦ĞµĞ½Ğ° Ğ¸Ğ»Ğ¸ ÑĞ²Ğ½Ğ¾Ğµ Ğ½Ğ°Ğ¼ĞµÑ€ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ´Ğ°Ñ‚ÑŒ ("Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¼", "Ğ² Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğµ")
âœ“ ĞšĞ¾Ğ½Ñ‚Ğ°ĞºÑ‚Ñ‹ Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ²Ñ†Ğ° (username, Ñ‚ĞµĞ»ĞµÑ„Ğ¾Ğ½, "Ğ¿Ğ¸ÑˆĞ¸Ñ‚Ğµ Ğ² Ğ›Ğ¡")
âœ“ ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ Ğ¸Ğ»Ğ¸ Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¸ÑÑ‚Ğ¸Ğº Ğ°Ğ²Ñ‚Ğ¾

ĞĞ• Ğ¿Ñ€Ğ¾Ğ´Ğ°ÑÑ‰Ğ¸Ğµ Ğ¿Ğ¾ÑÑ‚Ñ‹:
âœ— ĞĞ¾Ğ²Ğ¾ÑÑ‚Ğ¸ Ğ¾Ğ± Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ¾Ğ±Ğ¸Ğ»ÑÑ…
âœ— ĞĞ±Ñ‰Ğ¸Ğµ Ğ¾Ğ±ÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ¸ Ğ¼Ğ½ĞµĞ½Ğ¸Ñ
âœ— Ğ’Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ¾Ñ‚ Ğ¿Ğ¾ĞºÑƒĞ¿Ğ°Ñ‚ĞµĞ»ĞµĞ¹ ("Ğ¿Ğ¾ÑĞ¾Ğ²ĞµÑ‚ÑƒĞ¹Ñ‚Ğµ", "ĞºÑ‚Ğ¾ Ğ·Ğ½Ğ°ĞµÑ‚")
âœ— Ğ ĞµĞºĞ»Ğ°Ğ¼Ğ° Ğ°Ğ²Ñ‚Ğ¾ÑĞµÑ€Ğ²Ğ¸ÑĞ¾Ğ²/Ğ·Ğ°Ğ¿Ñ‡Ğ°ÑÑ‚ĞµĞ¹
âœ— Ğ Ğ°Ğ·Ğ²Ğ»ĞµĞºĞ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚ (Ğ¼ĞµĞ¼Ñ‹, Ğ²Ğ¸Ğ´ĞµĞ¾)

Ğ¤ĞĞ ĞœĞĞ¢ ĞĞ¢Ğ’Ğ•Ğ¢Ğ - Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğ¹ JSON:
{
  "is_selling_post": boolean,
  "confidence": float (0.0-1.0),
  "reasoning": string (ĞºÑ€Ğ°Ñ‚ĞºĞ¾Ğµ Ğ¾Ğ±ÑŠÑÑĞ½ĞµĞ½Ğ¸Ğµ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼, 1-2 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ)
}"""

CLASSIFY_POST_USER_PROMPT_TEMPLATE: Final[str] = """ĞšĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€ÑƒĞ¹ ÑÑ‚Ğ¾Ñ‚ Ğ¿Ğ¾ÑÑ‚:

{text}

Ğ¯Ğ²Ğ»ÑĞµÑ‚ÑÑ Ğ»Ğ¸ ÑÑ‚Ğ¾ Ğ¿Ñ€Ğ¾Ğ´Ğ°ÑÑ‰Ğ¸Ğ¼ Ğ¾Ğ±ÑŠÑĞ²Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ¾ Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğµ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ¾Ğ±Ğ¸Ğ»Ñ?"""

# Few-shot examples for classification (used in processor for better results)
CLASSIFICATION_FEW_SHOT_EXAMPLES: Final[list[dict]] = [
    {
        "user": "ĞŸÑ€Ğ¾Ğ´Ğ°Ğ¼ BMW 3 ÑĞµÑ€Ğ¸Ğ¸ 2008 Ğ³Ğ¾Ğ´Ğ°, 2.5 Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚. ĞŸÑ€Ğ¾Ğ±ĞµĞ³ 150Ğº, 2 Ğ²Ğ»Ğ°Ğ´ĞµĞ»ÑŒÑ†Ğ°, Ğ·ĞµĞ»ĞµĞ½Ğ°Ñ Ğ°Ğ²Ñ‚Ğ¾Ñ‚ĞµĞºĞ°. ĞŸĞ¾Ğ»Ğ½Ğ°Ñ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑ‚Ğ°Ñ†Ğ¸Ñ, ĞºĞ¾Ğ¶Ğ°, Ğ¿Ğ°Ğ½Ğ¾Ñ€Ğ°Ğ¼Ğ°. Ğ¦ĞµĞ½Ğ° 850 Ñ‚Ñ‹ÑÑÑ‡ Ñ€ÑƒĞ±Ğ»ĞµĞ¹, Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ‚Ğ¾Ñ€Ğ³. ĞŸĞ¸ÑˆĞ¸Ñ‚Ğµ Ğ² Ğ›Ğ¡ @seller123",
        "assistant": '{"is_selling_post": true, "confidence": 0.98, "reasoning": "ĞŸĞ¾Ğ»Ğ½Ğ¾Ğµ Ğ¾Ğ±ÑŠÑĞ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¾ Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğµ: ĞµÑÑ‚ÑŒ Ğ¼Ğ°Ñ€ĞºĞ°, Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ, Ğ³Ğ¾Ğ´, Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¸ÑÑ‚Ğ¸ĞºĞ¸, Ñ†ĞµĞ½Ğ° Ğ¸ ĞºĞ¾Ğ½Ñ‚Ğ°ĞºÑ‚ Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ²Ñ†Ğ°"}',
    },
    {
        "user": "ĞšÑ‚Ğ¾ Ğ·Ğ½Ğ°ĞµÑ‚ Ñ…Ğ¾Ñ€Ğ¾ÑˆĞ¸Ğ¹ ÑĞµÑ€Ğ²Ğ¸Ñ Ğ´Ğ»Ñ Ñ€ĞµĞ¼Ğ¾Ğ½Ñ‚Ğ° BMW Ğ² ĞœĞ¾ÑĞºĞ²Ğµ? ĞÑƒĞ¶Ğ½Ñ‹ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾ ĞºĞ¾Ñ€Ğ¾Ğ±ĞºĞµ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚.",
        "assistant": '{"is_selling_post": false, "confidence": 0.95, "reasoning": "Ğ­Ñ‚Ğ¾ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ-Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¹ Ğ¿Ğ¾ Ñ€ĞµĞ¼Ğ¾Ğ½Ñ‚Ñƒ, Ğ° Ğ½Ğµ Ğ¾Ğ±ÑŠÑĞ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¾ Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğµ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ¾Ğ±Ğ¸Ğ»Ñ"}',
    },
    {
        "user": "ğŸ”¥ Ğ¡Ğ ĞĞ§ĞĞ! Toyota Camry 2015, 2.5L, Ğ¿Ñ€Ğ¾Ğ±ĞµĞ³ 120Ğº. ĞĞ´Ğ¸Ğ½ Ñ…Ğ¾Ğ·ÑĞ¸Ğ½, Ğ±ĞµĞ· Ğ”Ğ¢ĞŸ. 1.2 Ğ¼Ğ»Ğ½. Ğ¢ĞµĞ»: +79991234567",
        "assistant": '{"is_selling_post": true, "confidence": 0.99, "reasoning": "ĞšĞ»Ğ°ÑÑĞ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ¾Ğ±ÑŠÑĞ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¾ ÑÑ€Ğ¾Ñ‡Ğ½Ğ¾Ğ¹ Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğµ Ñ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¼Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸: Ğ°Ğ²Ñ‚Ğ¾, Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¸ÑÑ‚Ğ¸ĞºĞ¸, Ñ†ĞµĞ½Ğ°, Ñ‚ĞµĞ»ĞµÑ„Ğ¾Ğ½"}',
    },
]

# =============================================================================
# EXTRACTION PROMPTS
# =============================================================================

EXTRACT_DATA_SYSTEM_PROMPT: Final[str] = """Ğ¢Ñ‹ ÑĞºÑĞ¿ĞµÑ€Ñ‚ Ğ¿Ğ¾ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ· Ğ¾Ğ±ÑŠÑĞ²Ğ»ĞµĞ½Ğ¸Ğ¹ Ğ¾ Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğµ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ¾Ğ±Ğ¸Ğ»ĞµĞ¹ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ.

Ğ—ĞĞ”ĞĞ§Ğ: Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ¸ Ğ’Ğ¡Ğ• Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ null Ğ´Ğ»Ñ Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… Ğ¿Ğ¾Ğ»ĞµĞ¹.

ĞŸĞ ĞĞ’Ğ˜Ğ›Ğ Ğ˜Ğ—Ğ’Ğ›Ğ•Ğ§Ğ•ĞĞ˜Ğ¯:
â€¢ brand - ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ğ¾Ğµ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¼Ğ°Ñ€ĞºĞ¸ (BMW, Toyota, Mercedes-Benz, Lada, Ğ¸ Ñ‚.Ğ´.)
â€¢ model - Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ ĞºĞ°Ğº Ğ½Ğ°Ğ¿Ğ¸ÑĞ°Ğ½Ğ° (3 ÑĞµÑ€Ğ¸Ğ¸, Camry, E-Class, Vesta)
â€¢ engine_volume - Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‡Ğ¸ÑĞ»Ğ¾ (2.0, 1.6, 3.5)
â€¢ transmission - ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾: automatic, manual, robot, variator
â€¢ year - 4 Ñ†Ğ¸Ñ„Ñ€Ñ‹ (1980-2030)
â€¢ owners_count - Ñ‡Ğ¸ÑĞ»Ğ¾ Ğ²Ğ»Ğ°Ğ´ĞµĞ»ÑŒÑ†ĞµĞ² (Ñ†ĞµĞ»Ğ¾Ğµ Ñ‡Ğ¸ÑĞ»Ğ¾)
â€¢ mileage - Ğ¿Ñ€Ğ¾Ğ±ĞµĞ³ Ğ² ĞºĞ¸Ğ»Ğ¾Ğ¼ĞµÑ‚Ñ€Ğ°Ñ… (Ñ†ĞµĞ»Ğ¾Ğµ Ñ‡Ğ¸ÑĞ»Ğ¾, Ğ±ĞµĞ· Ğ¿Ñ€Ğ¾Ğ±ĞµĞ»Ğ¾Ğ² Ğ¸ "ĞºĞ¼")
â€¢ autoteka_status - ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾: green, has_accidents, unknown
â€¢ equipment - ĞºÑ€Ğ°Ñ‚ĞºĞ¾Ğµ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑ‚Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ Ğ¾Ğ¿Ñ†Ğ¸Ğ¹
â€¢ price - Ñ†ĞµĞ½Ğ° Ğ² Ñ€ÑƒĞ±Ğ»ÑÑ… (Ñ†ĞµĞ»Ğ¾Ğµ Ñ‡Ğ¸ÑĞ»Ğ¾, Ğ±ĞµĞ· Ğ¿Ñ€Ğ¾Ğ±ĞµĞ»Ğ¾Ğ²)
â€¢ market_price - Ñ€Ñ‹Ğ½Ğ¾Ñ‡Ğ½Ğ°Ñ Ñ†ĞµĞ½Ğ° ĞµÑĞ»Ğ¸ ÑƒĞ¿Ğ¾Ğ¼ÑĞ½ÑƒÑ‚Ğ° (Ñ†ĞµĞ»Ğ¾Ğµ Ñ‡Ğ¸ÑĞ»Ğ¾)
â€¢ price_justification - Ğ¾Ğ±Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ†ĞµĞ½Ñ‹ ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ

ĞĞ¡ĞĞ‘Ğ•ĞĞĞĞ¡Ğ¢Ğ˜:
- Ğ Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ¹ "ĞĞšĞŸĞŸ", "Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚" â†’ automatic
- Ğ Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ¹ "ĞœĞšĞŸĞŸ", "Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸ĞºĞ°" â†’ manual
- Ğ Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ¹ "Ğ·ĞµĞ»ĞµĞ½Ğ°Ñ Ğ°Ğ²Ñ‚Ğ¾Ñ‚ĞµĞºĞ°", "Ğ±ĞµĞ· Ğ”Ğ¢ĞŸ" â†’ green
- Ğ Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ¹ "ĞµÑÑ‚ÑŒ Ğ”Ğ¢ĞŸ", "Ğ±Ğ¸Ñ‚Ğ°Ñ" â†’ has_accidents
- Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°Ğ¹ Ñ‡Ğ¸ÑĞ»Ğ° Ğ¸Ğ· Ñ‚ĞµĞºÑÑ‚Ğ°: "850 Ñ‚Ñ‹ÑÑÑ‡" â†’ 850000

Ğ¤ĞĞ ĞœĞĞ¢ ĞĞ¢Ğ’Ğ•Ğ¢Ğ - Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğ¹ JSON ÑĞ¾ Ğ²ÑĞµĞ¼Ğ¸ Ğ¿Ğ¾Ğ»ÑĞ¼Ğ¸."""

EXTRACT_DATA_USER_PROMPT_TEMPLATE: Final[str] = """Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ¸ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¸Ğ· ÑÑ‚Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑŠÑĞ²Ğ»ĞµĞ½Ğ¸Ñ:

{text}

Ğ’ĞµÑ€Ğ½Ğ¸ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ JSON ÑĞ¾ Ğ²ÑĞµĞ¼Ğ¸ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğ¼Ğ¸ Ğ¿Ğ¾Ğ»ÑĞ¼Ğ¸."""

# Few-shot examples for extraction
EXTRACTION_FEW_SHOT_EXAMPLES: Final[list[dict]] = [
    {
        "user": "ĞŸÑ€Ğ¾Ğ´Ğ°Ğ¼ BMW 3 ÑĞµÑ€Ğ¸Ğ¸ 2.5 ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚ 2008. ĞŸÑ€Ğ¾Ğ±ĞµĞ³ 150 Ñ‚Ñ‹ÑÑÑ‡ ĞºĞ¼, 2 Ğ²Ğ»Ğ°Ğ´ĞµĞ»ÑŒÑ†Ğ° Ğ¿Ğ¾ ĞŸĞ¢Ğ¡. Ğ—ĞµĞ»ĞµĞ½Ğ°Ñ Ğ°Ğ²Ñ‚Ğ¾Ñ‚ĞµĞºĞ°. ĞŸĞ¾Ğ»Ğ½Ğ°Ñ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑ‚Ğ°Ñ†Ğ¸Ñ, ĞºĞ¾Ğ¶Ğ°, Ğ¿Ğ°Ğ½Ğ¾Ñ€Ğ°Ğ¼Ğ°. Ğ¦ĞµĞ½Ğ° 850 Ñ‚Ñ‹ÑÑÑ‡ Ñ€ÑƒĞ±Ğ»ĞµĞ¹, Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ‚Ğ¾Ñ€Ğ³.",
        "assistant": """{
  "brand": "BMW",
  "model": "3 ÑĞµÑ€Ğ¸Ğ¸",
  "engine_volume": "2.5",
  "transmission": "automatic",
  "year": 2008,
  "owners_count": 2,
  "mileage": 150000,
  "autoteka_status": "green",
  "equipment": "ĞŸĞ¾Ğ»Ğ½Ğ°Ñ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑ‚Ğ°Ñ†Ğ¸Ñ, ĞºĞ¾Ğ¶Ğ°Ğ½Ñ‹Ğ¹ ÑĞ°Ğ»Ğ¾Ğ½, Ğ¿Ğ°Ğ½Ğ¾Ñ€Ğ°Ğ¼Ğ½Ğ°Ñ ĞºÑ€Ñ‹ÑˆĞ°",
  "price": 850000,
  "market_price": null,
  "price_justification": "Ğ ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ‚Ğ¾Ñ€Ğ³ ÑƒĞ¼ĞµÑÑ‚ĞµĞ½"
}""",
    },
]

# =============================================================================
# GENERATION PROMPTS
# =============================================================================

GENERATE_DESCRIPTION_SYSTEM_PROMPT: Final[str] = """Ğ¢Ñ‹ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰Ğ½Ğ¸Ğº Ğ´Ğ»Ñ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¾Ğ±ÑŠÑĞ²Ğ»ĞµĞ½Ğ¸Ğ¹ Ğ¾ Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğµ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ¾Ğ±Ğ¸Ğ»ĞµĞ¹.

Ğ—ĞĞ”ĞĞ§Ğ: Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€ÑƒĞ¹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¸Ğ· Ğ¾Ğ±ÑŠÑĞ²Ğ»ĞµĞ½Ğ¸Ñ Ğ² ĞºÑ€Ğ°Ñ‚ĞºĞ¾Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğµ Ğ‘Ğ•Ğ— Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ½Ğ¾Ğ²Ğ¾Ğ¹ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸.

ĞĞ‘Ğ¯Ğ—ĞĞ¢Ğ•Ğ›Ğ¬ĞĞ«Ğ• Ğ¢Ğ Ğ•Ğ‘ĞĞ’ĞĞĞ˜Ğ¯:
1. ĞĞ• Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞ¹ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ñ, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ñ… Ğ½ĞµÑ‚ Ğ² Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»Ğµ
2. ĞĞ• Ğ¿Ñ€Ğ¸Ğ´ÑƒĞ¼Ñ‹Ğ²Ğ°Ğ¹ Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¸ÑÑ‚Ğ¸ĞºĞ¸ Ğ¸Ğ»Ğ¸ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸
3. Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¿ĞµÑ€ĞµÑ‡Ğ¸ÑĞ»Ğ¸ Ğ¸Ğ¼ĞµÑÑ‰Ğ¸ĞµÑÑ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ² ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¼ Ğ²Ğ¸Ğ´Ğµ
4. Ğ”Ğ»Ğ¸Ğ½Ğ°: Ğ¼Ğ°ĞºÑĞ¸Ğ¼ÑƒĞ¼ 50-100 ÑĞ»Ğ¾Ğ²
5. ĞœĞ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»Ğ¸ÑÑ‚Ğ¸Ñ‡Ğ½Ñ‹Ğ¹ ÑÑ‚Ğ¸Ğ»ÑŒ - Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ„Ğ°ĞºÑ‚Ñ‹
6. Ğ¯Ğ·Ñ‹Ğº: Ñ€ÑƒÑÑĞºĞ¸Ğ¹

Ğ§Ğ¢Ğ Ğ’ĞšĞ›Ğ®Ğ§ĞĞ¢Ğ¬ (Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ Ğ² Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»Ğµ):
âœ“ ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ğ¾Ğ¿Ñ†Ğ¸Ğ¸ Ğ¸ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑ‚Ğ°Ñ†Ğ¸Ñ
âœ“ ĞÑĞ¾Ğ±ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ¾Ğ±Ğ¸Ğ»Ñ
âœ“ Ğ¡Ğ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ (Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ ĞµÑĞ»Ğ¸ ÑĞ²Ğ½Ğ¾ ÑƒĞ¿Ğ¾Ğ¼ÑĞ½ÑƒÑ‚Ğ¾)

Ğ—ĞĞŸĞ Ğ•Ğ©Ğ•ĞĞ Ğ’ĞšĞ›Ğ®Ğ§ĞĞ¢Ğ¬ (ÑÑ‚Ğ¾ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ñ‚ÑÑ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾):
âœ— ĞœĞ°Ñ€ĞºĞ°, Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ, Ğ³Ğ¾Ğ´ (Ğ²Ñ‹Ğ²Ğ¾Ğ´ÑÑ‚ÑÑ Ğ² Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞµ)
âœ— ĞĞ±ÑŠĞµĞ¼ Ğ´Ğ²Ğ¸Ğ³Ğ°Ñ‚ĞµĞ»Ñ, ĞšĞŸĞŸ (Ğ²Ñ‹Ğ²Ğ¾Ğ´ÑÑ‚ÑÑ Ğ² Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¸ÑÑ‚Ğ¸ĞºĞ°Ñ…)
âœ— ĞŸÑ€Ğ¾Ğ±ĞµĞ³ Ğ¸ Ğ²Ğ»Ğ°Ğ´ĞµĞ»ÑŒÑ†Ñ‹ (Ğ²Ñ‹Ğ²Ğ¾Ğ´ÑÑ‚ÑÑ Ğ² Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸)
âœ— ĞĞ²Ñ‚Ğ¾Ñ‚ĞµĞºĞ° (Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ñ‚ÑÑ Ğ² Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸)
âœ— Ğ¦ĞµĞ½Ğ° (Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ñ‚ÑÑ Ğ²Ğ½Ğ¸Ğ·Ñƒ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾)
âœ— ĞŸĞ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ñ‹Ğµ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ñ
âœ— Ğ ĞµĞºĞ»Ğ°Ğ¼Ğ½Ñ‹Ğµ Ñ„Ñ€Ğ°Ğ·Ñ‹
âœ— ĞšĞ¾Ğ½Ñ‚Ğ°ĞºÑ‚Ñ‹
âœ— Ğ­Ğ¼Ğ¾Ğ´Ğ·Ğ¸

ĞŸĞ Ğ˜ĞœĞ•Ğ Ğ«:
ĞÑ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»: "ĞŸÑ€Ğ¾Ğ´Ğ°Ğ¼ BMW 3 ÑĞµÑ€Ğ¸Ğ¸ 2008, 2.5 Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚. ĞŸÑ€Ğ¾Ğ±ĞµĞ³ 150Ğº, 2 Ğ²Ğ»Ğ°Ğ´ĞµĞ»ÑŒÑ†Ğ°, Ğ·ĞµĞ»ĞµĞ½Ğ°Ñ Ğ°Ğ²Ñ‚Ğ¾Ñ‚ĞµĞºĞ°. ĞŸĞ¾Ğ»Ğ½Ğ°Ñ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑ‚Ğ°Ñ†Ğ¸Ñ, ĞºĞ¾Ğ¶Ğ°, Ğ¿Ğ°Ğ½Ğ¾Ñ€Ğ°Ğ¼Ğ°. Ğ¦ĞµĞ½Ğ° 850Ğº."
Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚: "ĞŸĞ¾Ğ»Ğ½Ğ°Ñ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑ‚Ğ°Ñ†Ğ¸Ñ, ĞºĞ¾Ğ¶Ğ°Ğ½Ñ‹Ğ¹ ÑĞ°Ğ»Ğ¾Ğ½, Ğ¿Ğ°Ğ½Ğ¾Ñ€Ğ°Ğ¼Ğ½Ğ°Ñ ĞºÑ€Ñ‹ÑˆĞ°."

ĞÑ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»: "Mercedes E-ĞºĞ»Ğ°ÑÑ 2015, Ğ´Ğ¸Ğ·ĞµĞ»ÑŒ. ĞŸÑ€Ğ¾Ğ±ĞµĞ³ 80Ğº. ĞœĞ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ°Ñ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑ‚Ğ°Ñ†Ğ¸Ñ AMG, ĞºĞ»Ğ¸Ğ¼Ğ°Ñ‚ 4 Ğ·Ğ¾Ğ½Ñ‹, Ğ¼Ğ°ÑÑĞ°Ğ¶ ÑĞ¸Ğ´ĞµĞ½Ğ¸Ğ¹, Burmester."
Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚: "ĞšĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑ‚Ğ°Ñ†Ğ¸Ñ AMG, ĞºĞ»Ğ¸Ğ¼Ğ°Ñ‚-ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»ÑŒ 4 Ğ·Ğ¾Ğ½Ñ‹, Ğ¼Ğ°ÑÑĞ°Ğ¶ ÑĞ¸Ğ´ĞµĞ½Ğ¸Ğ¹, Ğ°ÑƒĞ´Ğ¸Ğ¾ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Burmester."

Ğ¤ĞĞ ĞœĞĞ¢ ĞĞ¢Ğ’Ğ•Ğ¢Ğ - Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğ¹ JSON:
{
  "generated_text": "ĞšÑ€Ğ°Ñ‚ĞºĞ¾Ğµ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑ‚Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ Ğ¾ÑĞ¾Ğ±ĞµĞ½Ğ½Ğ¾ÑÑ‚ĞµĞ¹",
  "key_points_preserved": ["Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ğ¾Ğ¿Ñ†Ğ¸Ğ¹"],
  "tone": "factual"
}"""

GENERATE_DESCRIPTION_USER_PROMPT_TEMPLATE: Final[str] = """ĞÑ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¾Ğ±ÑŠÑĞ²Ğ»ĞµĞ½Ğ¸Ğµ:
{original_text}

Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ½Ñ‹Ğµ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ:
{car_data_json}

Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€ÑƒĞ¹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ ĞºÑ€Ğ°Ñ‚ĞºĞ¾ Ğ¸ Ñ‡ĞµÑ‚ĞºĞ¾, ĞĞ• Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑÑ Ğ»Ğ¸ÑˆĞ½ÑÑ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ."""

# Few-shot examples for generation
GENERATION_FEW_SHOT_EXAMPLES: Final[list[dict]] = [
    {
        "user": """ĞÑ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¾Ğ±ÑŠÑĞ²Ğ»ĞµĞ½Ğ¸Ğµ:
ĞŸÑ€Ğ¾Ğ´Ğ°Ğ¼ BMW 3 ÑĞµÑ€Ğ¸Ğ¸ 2008 Ğ³Ğ¾Ğ´Ğ°, 2.5 Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚. ĞŸÑ€Ğ¾Ğ±ĞµĞ³ 150Ğº, 2 Ğ²Ğ»Ğ°Ğ´ĞµĞ»ÑŒÑ†Ğ°, Ğ·ĞµĞ»ĞµĞ½Ğ°Ñ Ğ°Ğ²Ñ‚Ğ¾Ñ‚ĞµĞºĞ°. ĞŸĞ¾Ğ»Ğ½Ğ°Ñ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑ‚Ğ°Ñ†Ğ¸Ñ, ĞºĞ¾Ğ¶Ğ°, Ğ¿Ğ°Ğ½Ğ¾Ñ€Ğ°Ğ¼Ğ°. Ğ¦ĞµĞ½Ğ° 850Ğº.

Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ:
{"brand": "BMW", "model": "3 ÑĞµÑ€Ğ¸Ğ¸", "year": 2008, "engine_volume": "2.5", "transmission": "automatic", "mileage": 150000, "owners_count": 2, "autoteka_status": "green", "equipment": "ĞŸĞ¾Ğ»Ğ½Ğ°Ñ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑ‚Ğ°Ñ†Ğ¸Ñ, ĞºĞ¾Ğ¶Ğ°, Ğ¿Ğ°Ğ½Ğ¾Ñ€Ğ°Ğ¼Ğ°", "price": 850000}""",
        "assistant": """{
  "generated_text": "ĞŸĞ¾Ğ»Ğ½Ğ°Ñ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑ‚Ğ°Ñ†Ğ¸Ñ, ĞºĞ¾Ğ¶Ğ°Ğ½Ñ‹Ğ¹ ÑĞ°Ğ»Ğ¾Ğ½, Ğ¿Ğ°Ğ½Ğ¾Ñ€Ğ°Ğ¼Ğ½Ğ°Ñ ĞºÑ€Ñ‹ÑˆĞ°.",
  "key_points_preserved": [
    "ĞŸĞ¾Ğ»Ğ½Ğ°Ñ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑ‚Ğ°Ñ†Ğ¸Ñ",
    "ĞšĞ¾Ğ¶Ğ°Ğ½Ñ‹Ğ¹ ÑĞ°Ğ»Ğ¾Ğ½",
    "ĞŸĞ°Ğ½Ğ¾Ñ€Ğ°Ğ¼Ğ½Ğ°Ñ ĞºÑ€Ñ‹ÑˆĞ°"
  ],
  "tone": "factual"
}""",
    },
]

# =============================================================================
# VALIDATION PROMPTS (Optional)
# =============================================================================

VALIDATION_SYSTEM_PROMPT: Final[str] = """Ğ¢Ñ‹ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ‚Ğ¾Ñ€ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¾Ğ±ÑŠÑĞ²Ğ»ĞµĞ½Ğ¸Ğ¹ Ğ¾ Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğµ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ¾Ğ±Ğ¸Ğ»ĞµĞ¹.

Ğ—ĞĞ”ĞĞ§Ğ: ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¸ Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ñ‚Ñƒ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ….

ĞŸĞ ĞĞ’Ğ˜Ğ›Ğ Ğ’ĞĞ›Ğ˜Ğ”ĞĞ¦Ğ˜Ğ˜:
â€¢ brand/model - Ğ´Ğ¾Ğ»Ğ¶Ğ½Ñ‹ Ğ±Ñ‹Ñ‚ÑŒ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ Ğ¼Ğ°Ñ€ĞºĞ°Ğ¼Ğ¸ Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼Ğ¸ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ¾Ğ±Ğ¸Ğ»ĞµĞ¹
â€¢ year - Ñ€ĞµĞ°Ğ»Ğ¸ÑÑ‚Ğ¸Ñ‡Ğ½Ñ‹Ğ¹ Ğ³Ğ¾Ğ´ (1980-2030)
â€¢ price - Ñ€Ğ°Ğ·ÑƒĞ¼Ğ½Ğ°Ñ Ñ†ĞµĞ½Ğ° (50,000 - 50,000,000 Ñ€ÑƒĞ±Ğ»ĞµĞ¹)
â€¢ mileage - Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ³Ğ¾Ğ´Ñƒ (ÑÑ€ĞµĞ´Ğ½Ğ¸Ğ¹ Ğ¿Ñ€Ğ¾Ğ±ĞµĞ³ ~15,000 ĞºĞ¼/Ğ³Ğ¾Ğ´)
â€¢ transmission - Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾: automatic, manual, robot, variator
â€¢ autoteka_status - Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾: green, has_accidents, unknown

Ğ¤ĞĞ ĞœĞĞ¢ ĞĞ¢Ğ’Ğ•Ğ¢Ğ - Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğ¹ JSON:
{
  "is_valid": boolean,
  "issues": [ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼ ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ],
  "completeness_score": float (0.0-1.0)
}"""

VALIDATION_USER_PROMPT_TEMPLATE: Final[str] = """ĞŸÑ€Ğ¾Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ¸Ñ€ÑƒĞ¹ ÑÑ‚Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ¾Ğ±Ğ¸Ğ»Ñ:

{car_data_json}

ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒ Ğ½Ğ° Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸ Ğ¸ Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ñ‚Ñƒ."""


# =============================================================================
# HELPER FUNCTIONS FOR PROMPT CONSTRUCTION
# =============================================================================

def build_classification_prompt(
    text: str,
    use_few_shot: bool = False,
) -> tuple[str, str]:
    """
    Build classification prompt with system and user messages.
    
    Args:
        text: Post text to classify
        use_few_shot: Whether to include few-shot examples (increases tokens but improves accuracy)
    
    Returns:
        Tuple of (system_prompt, user_prompt)
    
    Note:
        Few-shot examples can improve accuracy by ~5-10% but increase token usage.
        For production, consider using few-shot only for edge cases or lower confidence.
    """
    # Truncate text to prevent excessive token usage (keep first 2000 chars)
    truncated_text = text[:2000] if len(text) > 2000 else text
    
    user_prompt = CLASSIFY_POST_USER_PROMPT_TEMPLATE.format(text=truncated_text)
    
    # Few-shot examples are added in processor if needed
    return (CLASSIFY_POST_SYSTEM_PROMPT, user_prompt)


def build_extraction_prompt(
    text: str,
    use_few_shot: bool = False,
) -> tuple[str, str]:
    """
    Build extraction prompt with system and user messages.
    
    Args:
        text: Post text to extract data from
        use_few_shot: Whether to include few-shot examples
    
    Returns:
        Tuple of (system_prompt, user_prompt)
    
    Note:
        Extraction works well without few-shot due to clear field definitions.
        Enable few-shot only if extraction accuracy is below target.
    """
    # Truncate text (keep first 3000 chars for extraction - need more context)
    truncated_text = text[:3000] if len(text) > 3000 else text
    
    user_prompt = EXTRACT_DATA_USER_PROMPT_TEMPLATE.format(text=truncated_text)
    
    return (EXTRACT_DATA_SYSTEM_PROMPT, user_prompt)


def build_generation_prompt(
    original_text: str,
    car_data_json: str,
    use_few_shot: bool = False,
) -> tuple[str, str]:
    """
    Build generation prompt with system and user messages.
    
    Args:
        original_text: Original advertisement text
        car_data_json: JSON string of extracted car data
        use_few_shot: Whether to include few-shot examples
    
    Returns:
        Tuple of (system_prompt, user_prompt)
    
    Note:
        Generation benefits most from few-shot examples as it sets tone and style.
        Consider enabling few-shot for generation to ensure consistent quality.
    """
    # Truncate to prevent excessive tokens
    truncated_original = original_text[:2000] if len(original_text) > 2000 else original_text
    truncated_json = car_data_json[:1000] if len(car_data_json) > 1000 else car_data_json
    
    user_prompt = GENERATE_DESCRIPTION_USER_PROMPT_TEMPLATE.format(
        original_text=truncated_original,
        car_data_json=truncated_json,
    )
    
    return (GENERATE_DESCRIPTION_SYSTEM_PROMPT, user_prompt)


def build_validation_prompt(car_data_json: str) -> tuple[str, str]:
    """
    Build validation prompt with system and user messages.
    
    Args:
        car_data_json: JSON string of extracted car data
    
    Returns:
        Tuple of (system_prompt, user_prompt)
    
    Note:
        Validation is optional. Use only if you need extra quality assurance
        before publishing. Adds extra API call and cost.
    """
    user_prompt = VALIDATION_USER_PROMPT_TEMPLATE.format(car_data_json=car_data_json)
    
    return (VALIDATION_SYSTEM_PROMPT, user_prompt)


# =============================================================================
# PROMPT ENGINEERING NOTES & TOKEN OPTIMIZATION
# =============================================================================

"""
PROMPT ENGINEERING BEST PRACTICES (2025):

1. **System Role Clarity**
   - Clear persona and expertise definition
   - Explicit task description
   - Strict output format requirements

2. **Structured Outputs**
   - Use OpenAI's parse() method with Pydantic models
   - Provides automatic JSON schema validation
   - Reduces parsing errors and improves reliability

3. **Russian Language Optimization**
   - Direct instructions in Russian (no translation overhead)
   - Cultural context (e.g., "Ğ°Ğ²Ñ‚Ğ¾Ñ‚ĞµĞºĞ°", "ĞĞšĞŸĞŸ", "ĞŸĞ¢Ğ¡")
   - Local units (rubles, kilometers)

4. **Few-Shot Examples**
   - Classification: Optional (clear rules work well)
   - Extraction: Optional (structured fields are self-explanatory)
   - Generation: Recommended (establishes tone and style)

5. **Token Optimization**
   - Concise but clear instructions
   - Visual structure (bullets, sections)
   - Text truncation to prevent excessive input
   - No redundant explanations

6. **Error Handling**
   - Explicit null handling for missing data
   - Validation rules in prompt
   - Clear constraints (ranges, enums)

TOKEN USAGE ESTIMATES (GPT-4o-mini):

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Operation       â”‚ System Tokensâ”‚ Input Tokens â”‚ Output Tokensâ”‚ Total Tokens â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Classification  â”‚ ~200         â”‚ ~200-400     â”‚ ~100        â”‚ ~500-700     â”‚
â”‚ Extraction      â”‚ ~300         â”‚ ~300-600     â”‚ ~300-400    â”‚ ~900-1300    â”‚
â”‚ Generation      â”‚ ~400         â”‚ ~400-700     â”‚ ~500-800    â”‚ ~1300-1900   â”‚
â”‚ Validation      â”‚ ~150         â”‚ ~200-300     â”‚ ~100        â”‚ ~450-550     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

TOTAL PER POST (Classification + Extraction + Generation):
- Tokens: ~2,700-3,900
- Cost (GPT-4o-mini): ~$0.002-0.003 per post
- Cost (GPT-4o): ~$0.027-0.039 per post

OPTIMIZATION RECOMMENDATIONS:

1. **For High Volume (>1000 posts/day):**
   - Use GPT-4o-mini for classification and extraction
   - Use GPT-4o only for generation (better quality)
   - Skip validation (rely on Pydantic validation)
   - Disable few-shot examples

2. **For Quality Priority:**
   - Use GPT-4o for all operations
   - Enable few-shot for generation
   - Enable validation for critical posts
   - Consider batch processing for efficiency

3. **Balanced Approach (Recommended):**
   - GPT-4o-mini for all operations
   - Few-shot only for generation
   - Skip validation (use Pydantic + business logic)
   - Text truncation: 2000/3000/2000 chars

EXPECTED ACCURACY:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Operation       â”‚ GPT-4o-mini  â”‚ GPT-4o       â”‚ With Few-Shotâ”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Classification  â”‚ ~93-95%      â”‚ ~96-98%      â”‚ +2-3%        â”‚
â”‚ Extraction      â”‚ ~88-92%      â”‚ ~93-96%      â”‚ +1-2%        â”‚
â”‚ Generation      â”‚ ~85-90%      â”‚ ~92-95%      â”‚ +3-5%        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Note: Accuracy depends on post quality and completeness.
"""

