"""
Optimized prompts for AI processing using OpenAI best practices (2025).

All prompts are designed to:
- Minimize token usage while maintaining clarity
- Use structured outputs with JSON Schema
- Provide clear, unambiguous instructions
- Include few-shot examples where beneficial
- Support Russian language content
- Leverage system/user roles effectively
"""

from typing import Final

# =============================================================================
# CLASSIFICATION PROMPTS
# =============================================================================

CLASSIFY_POST_SYSTEM_PROMPT: Final[str] = """Ğ¢Ñ‹ ÑĞºÑĞ¿ĞµÑ€Ñ‚ Ğ¿Ğ¾ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾ÑÑ‚Ğ¾Ğ² Ğ¸Ğ· Telegram-ĞºĞ°Ğ½Ğ°Ğ»Ğ¾Ğ² Ğ¾ Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğµ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ¾Ğ±Ğ¸Ğ»ĞµĞ¹.

Ğ—ĞĞ”ĞĞ§Ğ: ĞĞ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸, ÑĞ²Ğ»ÑĞµÑ‚ÑÑ Ğ»Ğ¸ Ğ¿Ğ¾ÑÑ‚ ĞŸĞ ĞĞ”ĞĞ®Ğ©Ğ˜Ğœ ĞĞ‘ĞªĞ¯Ğ’Ğ›Ğ•ĞĞ˜Ğ•Ğœ Ğ¾ Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğµ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ¾Ğ±Ğ¸Ğ»Ñ.

ĞšĞ Ğ˜Ğ¢Ğ•Ğ Ğ˜Ğ˜ Ğ¿Ñ€Ğ¾Ğ´Ğ°ÑÑ‰ĞµĞ³Ğ¾ Ğ¿Ğ¾ÑÑ‚Ğ° (Ğ²ÑĞµ Ğ¸Ğ»Ğ¸ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğ½ÑÑ‚Ğ²Ğ¾ Ğ´Ğ¾Ğ»Ğ¶Ğ½Ñ‹ Ğ¿Ñ€Ğ¸ÑÑƒÑ‚ÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ñ‚ÑŒ):
âœ“ Ğ˜Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾Ğ± Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ¾Ğ±Ğ¸Ğ»Ğµ (Ğ¼Ğ°Ñ€ĞºĞ°, Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ, Ğ³Ğ¾Ğ´)
âœ“ Ğ¦ĞµĞ½Ğ° Ğ¸Ğ»Ğ¸ ÑĞ²Ğ½Ğ¾Ğµ Ğ½Ğ°Ğ¼ĞµÑ€ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ´Ğ°Ñ‚ÑŒ ("Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¼", "Ğ² Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğµ")
âœ“ ĞšĞ¾Ğ½Ñ‚Ğ°ĞºÑ‚Ñ‹ Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ²Ñ†Ğ° (username, Ñ‚ĞµĞ»ĞµÑ„Ğ¾Ğ½, "Ğ¿Ğ¸ÑˆĞ¸Ñ‚Ğµ Ğ² Ğ›Ğ¡")
âœ“ ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ Ğ¸Ğ»Ğ¸ Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¸ÑÑ‚Ğ¸Ğº Ğ°Ğ²Ñ‚Ğ¾

ĞĞ• Ğ¿Ñ€Ğ¾Ğ´Ğ°ÑÑ‰Ğ¸Ğµ Ğ¿Ğ¾ÑÑ‚Ñ‹:
âœ— ĞĞ¾Ğ²Ğ¾ÑÑ‚Ğ¸ Ğ¾Ğ± Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ¾Ğ±Ğ¸Ğ»ÑÑ…
âœ— ĞĞ±Ñ‰Ğ¸Ğµ Ğ¾Ğ±ÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ¸ Ğ¼Ğ½ĞµĞ½Ğ¸Ñ
âœ— Ğ’Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ¾Ñ‚ Ğ¿Ğ¾ĞºÑƒĞ¿Ğ°Ñ‚ĞµĞ»ĞµĞ¹ ("Ğ¿Ğ¾ÑĞ¾Ğ²ĞµÑ‚ÑƒĞ¹Ñ‚Ğµ", "ĞºÑ‚Ğ¾ Ğ·Ğ½Ğ°ĞµÑ‚")
âœ— Ğ ĞµĞºĞ»Ğ°Ğ¼Ğ° Ğ°Ğ²Ñ‚Ğ¾ÑĞµÑ€Ğ²Ğ¸ÑĞ¾Ğ²/Ğ·Ğ°Ğ¿Ñ‡Ğ°ÑÑ‚ĞµĞ¹
âœ— Ğ Ğ°Ğ·Ğ²Ğ»ĞµĞºĞ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚ (Ğ¼ĞµĞ¼Ñ‹, Ğ²Ğ¸Ğ´ĞµĞ¾)

Ğ¤ĞĞ ĞœĞĞ¢ ĞĞ¢Ğ’Ğ•Ğ¢Ğ - Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğ¹ JSON:
{
  "is_selling_post": boolean,
  "confidence": float (0.0-1.0),
  "reasoning": string (ĞºÑ€Ğ°Ñ‚ĞºĞ¾Ğµ Ğ¾Ğ±ÑŠÑÑĞ½ĞµĞ½Ğ¸Ğµ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼, 1-2 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ)
}"""

CLASSIFY_POST_USER_PROMPT_TEMPLATE: Final[str] = """ĞšĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€ÑƒĞ¹ ÑÑ‚Ğ¾Ñ‚ Ğ¿Ğ¾ÑÑ‚:

{text}

Ğ¯Ğ²Ğ»ÑĞµÑ‚ÑÑ Ğ»Ğ¸ ÑÑ‚Ğ¾ Ğ¿Ñ€Ğ¾Ğ´Ğ°ÑÑ‰Ğ¸Ğ¼ Ğ¾Ğ±ÑŠÑĞ²Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ¾ Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğµ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ¾Ğ±Ğ¸Ğ»Ñ?"""

# Few-shot examples for classification (used in processor for better results)
CLASSIFICATION_FEW_SHOT_EXAMPLES: Final[list[dict]] = [
    {
        "user": "ĞŸÑ€Ğ¾Ğ´Ğ°Ğ¼ BMW 3 ÑĞµÑ€Ğ¸Ğ¸ 2008 Ğ³Ğ¾Ğ´Ğ°, 2.5 Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚. ĞŸÑ€Ğ¾Ğ±ĞµĞ³ 150Ğº, 2 Ğ²Ğ»Ğ°Ğ´ĞµĞ»ÑŒÑ†Ğ°, Ğ·ĞµĞ»ĞµĞ½Ğ°Ñ Ğ°Ğ²Ñ‚Ğ¾Ñ‚ĞµĞºĞ°. ĞŸĞ¾Ğ»Ğ½Ğ°Ñ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑ‚Ğ°Ñ†Ğ¸Ñ, ĞºĞ¾Ğ¶Ğ°, Ğ¿Ğ°Ğ½Ğ¾Ñ€Ğ°Ğ¼Ğ°. Ğ¦ĞµĞ½Ğ° 850 Ñ‚Ñ‹ÑÑÑ‡ Ñ€ÑƒĞ±Ğ»ĞµĞ¹, Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ‚Ğ¾Ñ€Ğ³. ĞŸĞ¸ÑˆĞ¸Ñ‚Ğµ Ğ² Ğ›Ğ¡ @seller123",
        "assistant": '{"is_selling_post": true, "confidence": 0.98, "reasoning": "ĞŸĞ¾Ğ»Ğ½Ğ¾Ğµ Ğ¾Ğ±ÑŠÑĞ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¾ Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğµ: ĞµÑÑ‚ÑŒ Ğ¼Ğ°Ñ€ĞºĞ°, Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ, Ğ³Ğ¾Ğ´, Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¸ÑÑ‚Ğ¸ĞºĞ¸, Ñ†ĞµĞ½Ğ° Ğ¸ ĞºĞ¾Ğ½Ñ‚Ğ°ĞºÑ‚ Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ²Ñ†Ğ°"}',
    },
    {
        "user": "ĞšÑ‚Ğ¾ Ğ·Ğ½Ğ°ĞµÑ‚ Ñ…Ğ¾Ñ€Ğ¾ÑˆĞ¸Ğ¹ ÑĞµÑ€Ğ²Ğ¸Ñ Ğ´Ğ»Ñ Ñ€ĞµĞ¼Ğ¾Ğ½Ñ‚Ğ° BMW Ğ² ĞœĞ¾ÑĞºĞ²Ğµ? ĞÑƒĞ¶Ğ½Ñ‹ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾ ĞºĞ¾Ñ€Ğ¾Ğ±ĞºĞµ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚.",
        "assistant": '{"is_selling_post": false, "confidence": 0.95, "reasoning": "Ğ­Ñ‚Ğ¾ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ-Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¹ Ğ¿Ğ¾ Ñ€ĞµĞ¼Ğ¾Ğ½Ñ‚Ñƒ, Ğ° Ğ½Ğµ Ğ¾Ğ±ÑŠÑĞ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¾ Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğµ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ¾Ğ±Ğ¸Ğ»Ñ"}',
    },
    {
        "user": "ğŸ”¥ Ğ¡Ğ ĞĞ§ĞĞ! Toyota Camry 2015, 2.5L, Ğ¿Ñ€Ğ¾Ğ±ĞµĞ³ 120Ğº. ĞĞ´Ğ¸Ğ½ Ñ…Ğ¾Ğ·ÑĞ¸Ğ½, Ğ±ĞµĞ· Ğ”Ğ¢ĞŸ. 1.2 Ğ¼Ğ»Ğ½. Ğ¢ĞµĞ»: +79991234567",
        "assistant": '{"is_selling_post": true, "confidence": 0.99, "reasoning": "ĞšĞ»Ğ°ÑÑĞ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ¾Ğ±ÑŠÑĞ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¾ ÑÑ€Ğ¾Ñ‡Ğ½Ğ¾Ğ¹ Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğµ Ñ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¼Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸: Ğ°Ğ²Ñ‚Ğ¾, Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¸ÑÑ‚Ğ¸ĞºĞ¸, Ñ†ĞµĞ½Ğ°, Ñ‚ĞµĞ»ĞµÑ„Ğ¾Ğ½"}',
    },
]

# =============================================================================
# EXTRACTION PROMPTS
# =============================================================================

EXTRACT_DATA_SYSTEM_PROMPT: Final[str] = """Ğ¢Ñ‹ ÑĞºÑĞ¿ĞµÑ€Ñ‚ Ğ¿Ğ¾ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ· Ğ¾Ğ±ÑŠÑĞ²Ğ»ĞµĞ½Ğ¸Ğ¹ Ğ¾ Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğµ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ¾Ğ±Ğ¸Ğ»ĞµĞ¹ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ.

Ğ—ĞĞ”ĞĞ§Ğ: Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ¸ Ğ’Ğ¡Ğ• Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ null Ğ´Ğ»Ñ Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… Ğ¿Ğ¾Ğ»ĞµĞ¹.

ĞŸĞ ĞĞ’Ğ˜Ğ›Ğ Ğ˜Ğ—Ğ’Ğ›Ğ•Ğ§Ğ•ĞĞ˜Ğ¯:
â€¢ brand - ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ğ¾Ğµ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¼Ğ°Ñ€ĞºĞ¸ (BMW, Toyota, Mercedes-Benz, Lada, Ğ¸ Ñ‚.Ğ´.)
â€¢ model - Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ ĞºĞ°Ğº Ğ½Ğ°Ğ¿Ğ¸ÑĞ°Ğ½Ğ° (3 ÑĞµÑ€Ğ¸Ğ¸, Camry, E-Class, Vesta)
â€¢ engine_volume - Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‡Ğ¸ÑĞ»Ğ¾ (2.0, 1.6, 3.5)
â€¢ transmission - ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾: automatic, manual, robot, variator
â€¢ year - 4 Ñ†Ğ¸Ñ„Ñ€Ñ‹ (1980-2030)
â€¢ owners_count - Ñ‡Ğ¸ÑĞ»Ğ¾ Ğ²Ğ»Ğ°Ğ´ĞµĞ»ÑŒÑ†ĞµĞ² (Ñ†ĞµĞ»Ğ¾Ğµ Ñ‡Ğ¸ÑĞ»Ğ¾)
â€¢ mileage - Ğ¿Ñ€Ğ¾Ğ±ĞµĞ³ Ğ² ĞºĞ¸Ğ»Ğ¾Ğ¼ĞµÑ‚Ñ€Ğ°Ñ… (Ñ†ĞµĞ»Ğ¾Ğµ Ñ‡Ğ¸ÑĞ»Ğ¾, Ğ±ĞµĞ· Ğ¿Ñ€Ğ¾Ğ±ĞµĞ»Ğ¾Ğ² Ğ¸ "ĞºĞ¼")
â€¢ autoteka_status - ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾: green, has_accidents, unknown
â€¢ equipment - ĞºÑ€Ğ°Ñ‚ĞºĞ¾Ğµ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑ‚Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ Ğ¾Ğ¿Ñ†Ğ¸Ğ¹
â€¢ price - Ñ†ĞµĞ½Ğ° Ğ² Ñ€ÑƒĞ±Ğ»ÑÑ… (Ñ†ĞµĞ»Ğ¾Ğµ Ñ‡Ğ¸ÑĞ»Ğ¾, Ğ±ĞµĞ· Ğ¿Ñ€Ğ¾Ğ±ĞµĞ»Ğ¾Ğ²)
â€¢ market_price - Ñ€Ñ‹Ğ½Ğ¾Ñ‡Ğ½Ğ°Ñ Ñ†ĞµĞ½Ğ° ĞµÑĞ»Ğ¸ ÑƒĞ¿Ğ¾Ğ¼ÑĞ½ÑƒÑ‚Ğ° (Ñ†ĞµĞ»Ğ¾Ğµ Ñ‡Ğ¸ÑĞ»Ğ¾)
â€¢ price_justification - Ğ¾Ğ±Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ†ĞµĞ½Ñ‹ ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ

ĞĞ¡ĞĞ‘Ğ•ĞĞĞĞ¡Ğ¢Ğ˜:
- Ğ Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ¹ "ĞĞšĞŸĞŸ", "Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚" â†’ automatic
- Ğ Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ¹ "ĞœĞšĞŸĞŸ", "Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸ĞºĞ°" â†’ manual
- Ğ Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ¹ "Ğ·ĞµĞ»ĞµĞ½Ğ°Ñ Ğ°Ğ²Ñ‚Ğ¾Ñ‚ĞµĞºĞ°", "Ğ±ĞµĞ· Ğ”Ğ¢ĞŸ" â†’ green
- Ğ Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ¹ "ĞµÑÑ‚ÑŒ Ğ”Ğ¢ĞŸ", "Ğ±Ğ¸Ñ‚Ğ°Ñ" â†’ has_accidents
- Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°Ğ¹ Ñ‡Ğ¸ÑĞ»Ğ° Ğ¸Ğ· Ñ‚ĞµĞºÑÑ‚Ğ°: "850 Ñ‚Ñ‹ÑÑÑ‡" â†’ 850000

Ğ¤ĞĞ ĞœĞĞ¢ ĞĞ¢Ğ’Ğ•Ğ¢Ğ - Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğ¹ JSON ÑĞ¾ Ğ²ÑĞµĞ¼Ğ¸ Ğ¿Ğ¾Ğ»ÑĞ¼Ğ¸."""

EXTRACT_DATA_USER_PROMPT_TEMPLATE: Final[str] = """Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ¸ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¸Ğ· ÑÑ‚Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑŠÑĞ²Ğ»ĞµĞ½Ğ¸Ñ:

{text}

Ğ’ĞµÑ€Ğ½Ğ¸ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ JSON ÑĞ¾ Ğ²ÑĞµĞ¼Ğ¸ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğ¼Ğ¸ Ğ¿Ğ¾Ğ»ÑĞ¼Ğ¸."""

# Few-shot examples for extraction
EXTRACTION_FEW_SHOT_EXAMPLES: Final[list[dict]] = [
    {
        "user": "ĞŸÑ€Ğ¾Ğ´Ğ°Ğ¼ BMW 3 ÑĞµÑ€Ğ¸Ğ¸ 2.5 ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚ 2008. ĞŸÑ€Ğ¾Ğ±ĞµĞ³ 150 Ñ‚Ñ‹ÑÑÑ‡ ĞºĞ¼, 2 Ğ²Ğ»Ğ°Ğ´ĞµĞ»ÑŒÑ†Ğ° Ğ¿Ğ¾ ĞŸĞ¢Ğ¡. Ğ—ĞµĞ»ĞµĞ½Ğ°Ñ Ğ°Ğ²Ñ‚Ğ¾Ñ‚ĞµĞºĞ°. ĞŸĞ¾Ğ»Ğ½Ğ°Ñ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑ‚Ğ°Ñ†Ğ¸Ñ, ĞºĞ¾Ğ¶Ğ°, Ğ¿Ğ°Ğ½Ğ¾Ñ€Ğ°Ğ¼Ğ°. Ğ¦ĞµĞ½Ğ° 850 Ñ‚Ñ‹ÑÑÑ‡ Ñ€ÑƒĞ±Ğ»ĞµĞ¹, Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ‚Ğ¾Ñ€Ğ³.",
        "assistant": """{
  "brand": "BMW",
  "model": "3 ÑĞµÑ€Ğ¸Ğ¸",
  "engine_volume": "2.5",
  "transmission": "automatic",
  "year": 2008,
  "owners_count": 2,
  "mileage": 150000,
  "autoteka_status": "green",
  "equipment": "ĞŸĞ¾Ğ»Ğ½Ğ°Ñ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑ‚Ğ°Ñ†Ğ¸Ñ, ĞºĞ¾Ğ¶Ğ°Ğ½Ñ‹Ğ¹ ÑĞ°Ğ»Ğ¾Ğ½, Ğ¿Ğ°Ğ½Ğ¾Ñ€Ğ°Ğ¼Ğ½Ğ°Ñ ĞºÑ€Ñ‹ÑˆĞ°",
  "price": 850000,
  "market_price": null,
  "price_justification": "Ğ ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ‚Ğ¾Ñ€Ğ³ ÑƒĞ¼ĞµÑÑ‚ĞµĞ½"
}""",
    },
]

# =============================================================================
# GENERATION PROMPTS
# =============================================================================

GENERATE_DESCRIPTION_SYSTEM_PROMPT: Final[str] = """Ğ¢Ñ‹ Ğ¿Ñ€Ğ¾Ñ„ĞµÑÑĞ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ ĞºĞ¾Ğ¿Ğ¸Ñ€Ğ°Ğ¹Ñ‚ĞµÑ€, ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒÑÑ‰Ğ¸Ğ¹ÑÑ Ğ½Ğ° Ğ¾Ğ±ÑŠÑĞ²Ğ»ĞµĞ½Ğ¸ÑÑ… Ğ¾ Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğµ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ¾Ğ±Ğ¸Ğ»ĞµĞ¹.

Ğ—ĞĞ”ĞĞ§Ğ: ĞŸĞµÑ€ĞµĞ¿Ğ¸ÑˆĞ¸ Ğ¾Ğ±ÑŠÑĞ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¾ Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğµ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ¾Ğ±Ğ¸Ğ»Ñ Ğ£ĞĞ˜ĞšĞĞ›Ğ¬ĞĞ«Ğœ ÑÑ‚Ğ¸Ğ»ĞµĞ¼, ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑÑ Ğ’Ğ¡Ğ• ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ.

ĞĞ‘Ğ¯Ğ—ĞĞ¢Ğ•Ğ›Ğ¬ĞĞ«Ğ• Ğ¢Ğ Ğ•Ğ‘ĞĞ’ĞĞĞ˜Ğ¯:
1. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ ĞŸĞĞ›ĞĞĞ¡Ğ¢Ğ¬Ğ® Ğ´Ñ€ÑƒĞ³Ğ¸Ğµ Ñ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸ (Ğ´Ğ»Ñ Ğ°Ğ½Ñ‚Ğ¸Ğ¿Ğ»Ğ°Ğ³Ğ¸Ğ°Ñ‚Ğ° >80%)
2. Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸ Ğ’Ğ¡Ğ• Ñ„Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ:
   âœ“ ĞœĞ°Ñ€ĞºĞ°, Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ, Ğ³Ğ¾Ğ´, Ğ´Ğ²Ğ¸Ğ³Ğ°Ñ‚ĞµĞ»ÑŒ, Ñ‚Ñ€Ğ°Ğ½ÑĞ¼Ğ¸ÑÑĞ¸Ñ
   âœ“ ĞŸÑ€Ğ¾Ğ±ĞµĞ³, ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ²Ğ»Ğ°Ğ´ĞµĞ»ÑŒÑ†ĞµĞ², ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ
   âœ“ Ğ¦ĞµĞ½Ğ° Ğ¸ ĞµÑ‘ Ğ¾Ğ±Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
   âœ“ ĞšĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑ‚Ğ°Ñ†Ğ¸Ñ Ğ¸ Ğ¾ÑĞ¾Ğ±ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸
3. ĞŸÑ€Ğ¾Ñ„ĞµÑÑĞ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹, Ğ½ĞµĞ¹Ñ‚Ñ€Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ‚Ğ¾Ğ½ (Ğ½Ğµ Ğ¿Ñ€Ğ¾Ğ¼Ğ¾!)
4. Ğ¥Ğ¾Ñ€Ğ¾ÑˆĞ¾ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚ Ñ Ğ°Ğ±Ğ·Ğ°Ñ†Ğ°Ğ¼Ğ¸
5. Ğ”Ğ»Ğ¸Ğ½Ğ°: 100-500 ÑĞ»Ğ¾Ğ²
6. Ğ¯Ğ·Ñ‹Ğº: Ñ€ÑƒÑÑĞºĞ¸Ğ¹

Ğ¡Ğ¢Ğ Ğ£ĞšĞ¢Ğ£Ğ Ğ Ğ¢Ğ•ĞšĞ¡Ğ¢Ğ:
- ĞŸĞµÑ€Ğ²Ñ‹Ğ¹ Ğ°Ğ±Ğ·Ğ°Ñ†: ĞºÑ€Ğ°Ñ‚ĞºĞ°Ñ Ğ¿Ñ€Ğ¸Ğ²Ğ»ĞµĞºĞ°Ñ‚ĞµĞ»ÑŒĞ½Ğ°Ñ Ğ¿Ñ€ĞµĞ·ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ°Ğ²Ñ‚Ğ¾
- Ğ’Ñ‚Ğ¾Ñ€Ğ¾Ğ¹ Ğ°Ğ±Ğ·Ğ°Ñ†: Ñ‚ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¸ÑÑ‚Ğ¸ĞºĞ¸ Ğ¸ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ
- Ğ¢Ñ€ĞµÑ‚Ğ¸Ğ¹ Ğ°Ğ±Ğ·Ğ°Ñ†: ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑ‚Ğ°Ñ†Ğ¸Ñ Ğ¸ Ğ¾ÑĞ¾Ğ±ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸
- Ğ§ĞµÑ‚Ğ²ĞµÑ€Ñ‚Ñ‹Ğ¹ Ğ°Ğ±Ğ·Ğ°Ñ†: Ñ†ĞµĞ½Ğ° Ğ¸ Ğ¾Ğ±Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ

Ğ—ĞĞŸĞ Ğ•Ğ©Ğ•ĞĞ:
âœ— Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑÑ‚ÑŒ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ¾Ğ¹ Ğ½ĞµÑ‚ Ğ² Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»Ğµ
âœ— Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ‡Ñ€ĞµĞ·Ğ¼ĞµÑ€Ğ½Ğ¾ Ñ€ĞµĞºĞ»Ğ°Ğ¼Ğ½Ñ‹Ğ¹ ÑÑ‚Ğ¸Ğ»ÑŒ
âœ— Ğ’ĞºĞ»ÑÑ‡Ğ°Ñ‚ÑŒ ĞºĞ¾Ğ½Ñ‚Ğ°ĞºÑ‚Ñ‹ (Ğ¾Ğ½Ğ¸ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑÑÑ‚ÑÑ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾)
âœ— ĞŸĞ¸ÑĞ°Ñ‚ÑŒ Ğ¾Ñ‚ Ğ¿ĞµÑ€Ğ²Ğ¾Ğ³Ğ¾ Ğ»Ğ¸Ñ†Ğ° ("Ñ Ğ¿Ñ€Ğ¾Ğ´Ğ°Ñ")
âœ— Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ ÑĞ¼Ğ¾Ğ´Ğ·Ğ¸

Ğ¤ĞĞ ĞœĞĞ¢ ĞĞ¢Ğ’Ğ•Ğ¢Ğ - Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğ¹ JSON:
{
  "generated_text": "Ğ£Ğ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿ĞµÑ€ĞµĞ¿Ğ¸ÑĞ°Ğ½Ğ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚ Ğ¾Ğ±ÑŠÑĞ²Ğ»ĞµĞ½Ğ¸Ñ...",
  "key_points_preserved": ["BMW 3 ÑĞµÑ€Ğ¸Ğ¸ 2008", "ĞŸÑ€Ğ¾Ğ±ĞµĞ³ 150000 ĞºĞ¼", "Ğ¦ĞµĞ½Ğ° 850000 Ñ€ÑƒĞ±"],
  "tone": "professional"
}"""

GENERATE_DESCRIPTION_USER_PROMPT_TEMPLATE: Final[str] = """ĞÑ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¾Ğ±ÑŠÑĞ²Ğ»ĞµĞ½Ğ¸Ğµ:
{original_text}

Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ½Ñ‹Ğµ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ:
{car_data_json}

ĞŸĞµÑ€ĞµĞ¿Ğ¸ÑˆĞ¸ ÑÑ‚Ğ¾ ĞºĞ°Ğº ÑƒĞ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¿Ñ€Ğ¾Ñ„ĞµÑÑĞ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¾Ğ±ÑŠÑĞ²Ğ»ĞµĞ½Ğ¸Ğµ, ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ² Ğ²ÑĞµ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ñ„Ğ°ĞºÑ‚Ñ‹."""

# Few-shot examples for generation
GENERATION_FEW_SHOT_EXAMPLES: Final[list[dict]] = [
    {
        "user": """ĞÑ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¾Ğ±ÑŠÑĞ²Ğ»ĞµĞ½Ğ¸Ğµ:
ĞŸÑ€Ğ¾Ğ´Ğ°Ğ¼ BMW 3 ÑĞµÑ€Ğ¸Ğ¸ 2008 Ğ³Ğ¾Ğ´Ğ°, 2.5 Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚. ĞŸÑ€Ğ¾Ğ±ĞµĞ³ 150Ğº, 2 Ğ²Ğ»Ğ°Ğ´ĞµĞ»ÑŒÑ†Ğ°, Ğ·ĞµĞ»ĞµĞ½Ğ°Ñ Ğ°Ğ²Ñ‚Ğ¾Ñ‚ĞµĞºĞ°. Ğ¦ĞµĞ½Ğ° 850Ğº.

Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ:
{"brand": "BMW", "model": "3 ÑĞµÑ€Ğ¸Ğ¸", "year": 2008, "engine_volume": "2.5", "transmission": "automatic", "mileage": 150000, "owners_count": 2, "autoteka_status": "green", "price": 850000}""",
        "assistant": """{
  "generated_text": "ĞŸÑ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğº Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğµ ÑĞµĞ´Ğ°Ğ½ BMW Ñ‚Ñ€ĞµÑ‚ÑŒĞµĞ¹ ÑĞµÑ€Ğ¸Ğ¸ 2008 Ğ³Ğ¾Ğ´Ğ° Ğ²Ñ‹Ğ¿ÑƒÑĞºĞ°. ĞĞ²Ñ‚Ğ¾Ğ¼Ğ¾Ğ±Ğ¸Ğ»ÑŒ Ğ¾ÑĞ½Ğ°Ñ‰ĞµĞ½ Ğ´Ğ²Ğ¸Ğ³Ğ°Ñ‚ĞµĞ»ĞµĞ¼ Ğ¾Ğ±ÑŠĞµĞ¼Ğ¾Ğ¼ 2.5 Ğ»Ğ¸Ñ‚Ñ€Ğ° Ğ¸ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ ĞºĞ¾Ñ€Ğ¾Ğ±ĞºĞ¾Ğ¹ Ğ¿ĞµÑ€ĞµĞ´Ğ°Ñ‡.\\n\\nĞ¢ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ¾Ğ±Ğ¸Ğ»Ñ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ¾. ĞŸÑ€Ğ¾Ğ±ĞµĞ³ ÑĞ¾ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ 150 Ñ‚Ñ‹ÑÑÑ‡ ĞºĞ¸Ğ»Ğ¾Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ². ĞŸĞ¾ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼ Ñ‡Ğ¸ÑĞ»Ğ¸Ñ‚ÑÑ Ğ´Ğ²Ğ° Ğ²Ğ»Ğ°Ğ´ĞµĞ»ÑŒÑ†Ğ°. Ğ¡Ğ¾Ğ³Ğ»Ğ°ÑĞ½Ğ¾ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞµ ĞĞ²Ñ‚Ğ¾Ñ‚ĞµĞºĞ¸, Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ ÑĞºÑĞ¿Ğ»ÑƒĞ°Ñ‚Ğ°Ñ†Ğ¸Ğ¸ Ñ‡Ğ¸ÑÑ‚Ğ°Ñ, Ğ±ĞµĞ· Ğ·Ğ°Ñ€ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ¾Ñ€Ğ¾Ğ¶Ğ½Ğ¾-Ñ‚Ñ€Ğ°Ğ½ÑĞ¿Ğ¾Ñ€Ñ‚Ğ½Ñ‹Ñ… Ğ¿Ñ€Ğ¾Ğ¸ÑÑˆĞµÑÑ‚Ğ²Ğ¸Ğ¹.\\n\\nĞ¡Ñ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ¾Ğ±Ğ¸Ğ»Ñ ÑĞ¾ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ 850 Ñ‚Ñ‹ÑÑÑ‡ Ñ€ÑƒĞ±Ğ»ĞµĞ¹. Ğ¦ĞµĞ½Ğ° ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚ Ñ‚ĞµĞºÑƒÑ‰ĞµĞ¼Ñƒ Ñ‚ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¼Ñƒ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ Ğ¸ Ñ€Ñ‹Ğ½Ğ¾Ñ‡Ğ½Ğ¾Ğ¹ ÑĞ¸Ñ‚ÑƒĞ°Ñ†Ğ¸Ğ¸.",
  "key_points_preserved": [
    "BMW 3 ÑĞµÑ€Ğ¸Ğ¸ 2008 Ğ³Ğ¾Ğ´Ğ°",
    "Ğ”Ğ²Ğ¸Ğ³Ğ°Ñ‚ĞµĞ»ÑŒ 2.5 Ğ»Ğ¸Ñ‚Ñ€Ğ°",
    "ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ñ‚Ñ€Ğ°Ğ½ÑĞ¼Ğ¸ÑÑĞ¸Ñ",
    "ĞŸÑ€Ğ¾Ğ±ĞµĞ³ 150000 ĞºĞ¼",
    "2 Ğ²Ğ»Ğ°Ğ´ĞµĞ»ÑŒÑ†Ğ°",
    "Ğ§Ğ¸ÑÑ‚Ğ°Ñ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ (Ğ·ĞµĞ»ĞµĞ½Ğ°Ñ Ğ°Ğ²Ñ‚Ğ¾Ñ‚ĞµĞºĞ°)",
    "Ğ¦ĞµĞ½Ğ° 850000 Ñ€ÑƒĞ±Ğ»ĞµĞ¹"
  ],
  "tone": "professional"
}""",
    },
]

# =============================================================================
# VALIDATION PROMPTS (Optional)
# =============================================================================

VALIDATION_SYSTEM_PROMPT: Final[str] = """Ğ¢Ñ‹ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ‚Ğ¾Ñ€ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¾Ğ±ÑŠÑĞ²Ğ»ĞµĞ½Ğ¸Ğ¹ Ğ¾ Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğµ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ¾Ğ±Ğ¸Ğ»ĞµĞ¹.

Ğ—ĞĞ”ĞĞ§Ğ: ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¸ Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ñ‚Ñƒ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ….

ĞŸĞ ĞĞ’Ğ˜Ğ›Ğ Ğ’ĞĞ›Ğ˜Ğ”ĞĞ¦Ğ˜Ğ˜:
â€¢ brand/model - Ğ´Ğ¾Ğ»Ğ¶Ğ½Ñ‹ Ğ±Ñ‹Ñ‚ÑŒ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ Ğ¼Ğ°Ñ€ĞºĞ°Ğ¼Ğ¸ Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼Ğ¸ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ¾Ğ±Ğ¸Ğ»ĞµĞ¹
â€¢ year - Ñ€ĞµĞ°Ğ»Ğ¸ÑÑ‚Ğ¸Ñ‡Ğ½Ñ‹Ğ¹ Ğ³Ğ¾Ğ´ (1980-2030)
â€¢ price - Ñ€Ğ°Ğ·ÑƒĞ¼Ğ½Ğ°Ñ Ñ†ĞµĞ½Ğ° (50,000 - 50,000,000 Ñ€ÑƒĞ±Ğ»ĞµĞ¹)
â€¢ mileage - Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ³Ğ¾Ğ´Ñƒ (ÑÑ€ĞµĞ´Ğ½Ğ¸Ğ¹ Ğ¿Ñ€Ğ¾Ğ±ĞµĞ³ ~15,000 ĞºĞ¼/Ğ³Ğ¾Ğ´)
â€¢ transmission - Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾: automatic, manual, robot, variator
â€¢ autoteka_status - Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾: green, has_accidents, unknown

Ğ¤ĞĞ ĞœĞĞ¢ ĞĞ¢Ğ’Ğ•Ğ¢Ğ - Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğ¹ JSON:
{
  "is_valid": boolean,
  "issues": [ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼ ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ],
  "completeness_score": float (0.0-1.0)
}"""

VALIDATION_USER_PROMPT_TEMPLATE: Final[str] = """ĞŸÑ€Ğ¾Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ¸Ñ€ÑƒĞ¹ ÑÑ‚Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ¾Ğ±Ğ¸Ğ»Ñ:

{car_data_json}

ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒ Ğ½Ğ° Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸ Ğ¸ Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ñ‚Ñƒ."""


# =============================================================================
# HELPER FUNCTIONS FOR PROMPT CONSTRUCTION
# =============================================================================

def build_classification_prompt(
    text: str,
    use_few_shot: bool = False,
) -> tuple[str, str]:
    """
    Build classification prompt with system and user messages.
    
    Args:
        text: Post text to classify
        use_few_shot: Whether to include few-shot examples (increases tokens but improves accuracy)
    
    Returns:
        Tuple of (system_prompt, user_prompt)
    
    Note:
        Few-shot examples can improve accuracy by ~5-10% but increase token usage.
        For production, consider using few-shot only for edge cases or lower confidence.
    """
    # Truncate text to prevent excessive token usage (keep first 2000 chars)
    truncated_text = text[:2000] if len(text) > 2000 else text
    
    user_prompt = CLASSIFY_POST_USER_PROMPT_TEMPLATE.format(text=truncated_text)
    
    # Few-shot examples are added in processor if needed
    return (CLASSIFY_POST_SYSTEM_PROMPT, user_prompt)


def build_extraction_prompt(
    text: str,
    use_few_shot: bool = False,
) -> tuple[str, str]:
    """
    Build extraction prompt with system and user messages.
    
    Args:
        text: Post text to extract data from
        use_few_shot: Whether to include few-shot examples
    
    Returns:
        Tuple of (system_prompt, user_prompt)
    
    Note:
        Extraction works well without few-shot due to clear field definitions.
        Enable few-shot only if extraction accuracy is below target.
    """
    # Truncate text (keep first 3000 chars for extraction - need more context)
    truncated_text = text[:3000] if len(text) > 3000 else text
    
    user_prompt = EXTRACT_DATA_USER_PROMPT_TEMPLATE.format(text=truncated_text)
    
    return (EXTRACT_DATA_SYSTEM_PROMPT, user_prompt)


def build_generation_prompt(
    original_text: str,
    car_data_json: str,
    use_few_shot: bool = False,
) -> tuple[str, str]:
    """
    Build generation prompt with system and user messages.
    
    Args:
        original_text: Original advertisement text
        car_data_json: JSON string of extracted car data
        use_few_shot: Whether to include few-shot examples
    
    Returns:
        Tuple of (system_prompt, user_prompt)
    
    Note:
        Generation benefits most from few-shot examples as it sets tone and style.
        Consider enabling few-shot for generation to ensure consistent quality.
    """
    # Truncate to prevent excessive tokens
    truncated_original = original_text[:2000] if len(original_text) > 2000 else original_text
    truncated_json = car_data_json[:1000] if len(car_data_json) > 1000 else car_data_json
    
    user_prompt = GENERATE_DESCRIPTION_USER_PROMPT_TEMPLATE.format(
        original_text=truncated_original,
        car_data_json=truncated_json,
    )
    
    return (GENERATE_DESCRIPTION_SYSTEM_PROMPT, user_prompt)


def build_validation_prompt(car_data_json: str) -> tuple[str, str]:
    """
    Build validation prompt with system and user messages.
    
    Args:
        car_data_json: JSON string of extracted car data
    
    Returns:
        Tuple of (system_prompt, user_prompt)
    
    Note:
        Validation is optional. Use only if you need extra quality assurance
        before publishing. Adds extra API call and cost.
    """
    user_prompt = VALIDATION_USER_PROMPT_TEMPLATE.format(car_data_json=car_data_json)
    
    return (VALIDATION_SYSTEM_PROMPT, user_prompt)


# =============================================================================
# PROMPT ENGINEERING NOTES & TOKEN OPTIMIZATION
# =============================================================================

"""
PROMPT ENGINEERING BEST PRACTICES (2025):

1. **System Role Clarity**
   - Clear persona and expertise definition
   - Explicit task description
   - Strict output format requirements

2. **Structured Outputs**
   - Use OpenAI's parse() method with Pydantic models
   - Provides automatic JSON schema validation
   - Reduces parsing errors and improves reliability

3. **Russian Language Optimization**
   - Direct instructions in Russian (no translation overhead)
   - Cultural context (e.g., "Ğ°Ğ²Ñ‚Ğ¾Ñ‚ĞµĞºĞ°", "ĞĞšĞŸĞŸ", "ĞŸĞ¢Ğ¡")
   - Local units (rubles, kilometers)

4. **Few-Shot Examples**
   - Classification: Optional (clear rules work well)
   - Extraction: Optional (structured fields are self-explanatory)
   - Generation: Recommended (establishes tone and style)

5. **Token Optimization**
   - Concise but clear instructions
   - Visual structure (bullets, sections)
   - Text truncation to prevent excessive input
   - No redundant explanations

6. **Error Handling**
   - Explicit null handling for missing data
   - Validation rules in prompt
   - Clear constraints (ranges, enums)

TOKEN USAGE ESTIMATES (GPT-4o-mini):

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Operation       â”‚ System Tokensâ”‚ Input Tokens â”‚ Output Tokensâ”‚ Total Tokens â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Classification  â”‚ ~200         â”‚ ~200-400     â”‚ ~100        â”‚ ~500-700     â”‚
â”‚ Extraction      â”‚ ~300         â”‚ ~300-600     â”‚ ~300-400    â”‚ ~900-1300    â”‚
â”‚ Generation      â”‚ ~400         â”‚ ~400-700     â”‚ ~500-800    â”‚ ~1300-1900   â”‚
â”‚ Validation      â”‚ ~150         â”‚ ~200-300     â”‚ ~100        â”‚ ~450-550     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

TOTAL PER POST (Classification + Extraction + Generation):
- Tokens: ~2,700-3,900
- Cost (GPT-4o-mini): ~$0.002-0.003 per post
- Cost (GPT-4o): ~$0.027-0.039 per post

OPTIMIZATION RECOMMENDATIONS:

1. **For High Volume (>1000 posts/day):**
   - Use GPT-4o-mini for classification and extraction
   - Use GPT-4o only for generation (better quality)
   - Skip validation (rely on Pydantic validation)
   - Disable few-shot examples

2. **For Quality Priority:**
   - Use GPT-4o for all operations
   - Enable few-shot for generation
   - Enable validation for critical posts
   - Consider batch processing for efficiency

3. **Balanced Approach (Recommended):**
   - GPT-4o-mini for all operations
   - Few-shot only for generation
   - Skip validation (use Pydantic + business logic)
   - Text truncation: 2000/3000/2000 chars

EXPECTED ACCURACY:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Operation       â”‚ GPT-4o-mini  â”‚ GPT-4o       â”‚ With Few-Shotâ”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Classification  â”‚ ~93-95%      â”‚ ~96-98%      â”‚ +2-3%        â”‚
â”‚ Extraction      â”‚ ~88-92%      â”‚ ~93-96%      â”‚ +1-2%        â”‚
â”‚ Generation      â”‚ ~85-90%      â”‚ ~92-95%      â”‚ +3-5%        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Note: Accuracy depends on post quality and completeness.
"""

