# Система промптов для генерации проекта Cars Bot

## Общие принципы

- **Поэтапная генерация**: каждый промпт фокусируется на одном компоненте
- **Использование лучших практик**: ссылки на актуальную документацию через Context7
- **Минимальная перегрузка контекста**: четкие и конкретные запросы
- **Последовательность**: строгий порядок выполнения промптов

---

## Этап 1: Инициализация проекта

### Промпт 1.1: Структура проекта и зависимости

```
Создай структуру Python проекта для Telegram-бота мониторинга автомобильных объявлений согласно ТЗ в файле Tz.md.

Требования:
1. Современная структура с использованием src layout pattern
2. Docker Compose конфигурация для всех сервисов (bot, monitor, ai-processor, publisher, sheets-sync, postgres, redis)
3. Файл requirements.txt с точными версиями:
   - aiogram 3.x (для Bot API)
   - telethon (для User Session мониторинга)
   - gspread, google-auth (для Google Sheets)
   - sqlalchemy, alembic (для БД)
   - redis, celery (для очередей)
   - openai (для AI)
4. .env.example с описанием всех переменных окружения
5. .gitignore с исключением файлов сессий (.session)
6. pyproject.toml для управления проектом
7. README.md с инструкцией по первоначальной настройке

Используй лучшие практики Python разработки 2025 года.
```

**Контекст для Context7:**
- Запроси документацию: aiogram, telethon, gspread, sqlalchemy

---

## Этап 2: База данных

### Промпт 2.1: Модели SQLAlchemy

```
Создай SQLAlchemy модели для всех таблиц согласно разделу 3.2.1 ТЗ (Tz.md).

Таблицы:
- channels (мониторируемые каналы)
- posts (обработанные посты)
- car_data (структурированные данные авто)
- seller_contacts (контакты продавцов)
- users (пользователи бота)
- subscriptions (подписки)
- payments (платежи)
- contact_requests (запросы контактов)
- settings (настройки системы)

Требования:
1. Используй современные типы данных SQLAlchemy 2.0+
2. Правильные relationships и foreign keys
3. Indexes для часто используемых полей
4. Миксины для timestamp полей (created_at, updated_at)
5. Enum для статусов
6. Методы __repr__ для удобной отладки

Используй best practices SQLAlchemy согласно актуальной документации.
```

**Контекст для Context7:**
- Запроси: SQLAlchemy 2.0 best practices, relationship patterns

### Промпт 2.2: Alembic миграции

```
Создай начальную Alembic миграцию для всех моделей из предыдущего промпта.

Требования:
1. Настроенный alembic.ini
2. env.py с правильной конфигурацией для async SQLAlchemy
3. Первая миграция с созданием всех таблиц
4. Скрипт для автоматического применения миграций

Следуй best practices Alembic.
```

---

## Этап 3: Google Sheets Integration

### Промпт 3.1: Google Sheets Service

```
Создай модуль для работы с Google Sheets согласно разделам 2.5 и 6 ТЗ (Tz.md).

Функциональность:
1. Класс GoogleSheetsManager с методами:
   - get_channels() - чтение списка каналов для мониторинга
   - get_filter_settings() - чтение настроек фильтров
   - update_channel_stats() - обновление статистики канала
   - add_subscriber() - добавление подписчика
   - update_subscriber_status() - обновление статуса подписки
   - write_log() - запись в лог
   - write_analytics() - запись аналитики

2. Кэширование данных (60 секунд для настроек)
3. Обработка ошибок и rate limiting Google API
4. Batch-операции для оптимизации
5. Типизация с Pydantic моделями

Используй gspread best practices и актуальную документацию Google Sheets API v4.
```
id 11CK7WsMDHEju55Wr-ECtKstu_WReDYWlLCNHp8jBiQY

southern-camera-476019-f1-416755b5d8b7.json
**Контекст для Context7:**
- Запроси: gspread latest documentation, google-auth

### Промпт 3.2: Шаблон Google Таблицы

```
Создай Python скрипт для автоматического создания Google Таблицы с правильной структурой.

Скрипт должен создать листы:
1. "Каналы для мониторинга" - со столбцами из раздела 2.5.1 ТЗ
2. "Настройки фильтров" - из раздела 2.5.2
3. "Подписчики" - из раздела 2.5.3
4. "Аналитика" - из раздела 2.5.4
5. "Очередь публикаций" - из раздела 2.5.5
6. "Логи" - из раздела 2.5.6

Добавь:
- Форматирование заголовков (жирный шрифт, цвет фона)
- Замороженные строки заголовков
- Валидация данных (TRUE/FALSE для булевых полей)
- Примеры данных в первых строках (комментариями)

Используй gspread для создания и форматирования.
```

---

## Этап 4: Telegram User Session (мониторинг)

### Промпт 4.1: Telethon Monitor Service

```
Создай сервис мониторинга каналов через Telegram User Session согласно разделу 5 ТЗ (Tz.md).

Компоненты:

1. **Скрипт создания сессии** (scripts/create_session.py):
   - Интерактивная авторизация
   - Валидация api_id, api_hash
   - Сохранение сессии в безопасное место
   - 2FA поддержка

2. **Класс ChannelMonitor**:
   - Подключение через Telethon Client
   - Прослушивание новых сообщений в каналах из Google Sheets
   - Фильтрация по ключевым словам
   - Отправка в очередь на AI обработку
   - Защита от дублирования
   - Graceful reconnect при потере соединения

3. **Rate limiting и безопасность**:
   - Соблюдение лимитов Telegram API
   - Имитация человеческого поведения
   - Логирование всех действий

Используй Telethon best practices, async/await паттерны.
```

**Контекст для Context7:**
- Запроси: Telethon latest documentation, async patterns

### Промпт 4.2: Обработчик сообщений

```
Создай модуль обработки входящих сообщений из каналов.

Класс MessageProcessor должен:
1. Извлекать текст, медиа, метаданные
2. Проверять наличие в БД (защита от дублей)
3. Применять фильтры по ключевым словам
4. Извлекать контакты продавца (@username, номер телефона)
5. Формировать задачу для AI-обработки
6. Сохранять в БД с статусом "pending"

Используй Pydantic для валидации данных, async SQLAlchemy для БД.
```

---

## Этап 5: AI Processing Service

### Промпт 5.1: OpenAI Integration

```
Создай модуль AI обработки постов согласно разделу 2.2 ТЗ (Tz.md).

Класс AIProcessor с методами:

1. **classify_post(text)** - классификация стиля поста:
   - Промпт: определить продающий/информативный/развлекательный
   - Возврат: JSON с is_selling_post и confidence score
   
2. **extract_car_data(text)** - извлечение структурированных данных:
   - Промпт: извлечь марку, модель, год, пробег, цену и т.д.
   - Возврат: JSON со всеми полями из таблицы car_data
   
3. **generate_unique_description(original_text, car_data)** - генерация уникального текста:
   - Промпт: переписать в стандартизированном формате
   - Сохранить всю ключевую информацию
   - Профессиональный тон
   - Возврат: уникальный текст для публикации

Требования:
- Обработка ошибок OpenAI API
- Retry логика с экспоненциальным backoff
- Логирование всех запросов и ответов
- Оптимизация токенов (использовать эффективные промпты)

Используй актуальную OpenAI API (версия 1.x+), best practices для промптов.
```

**Контекст для Context7:**
- Запроси: OpenAI Python library latest, prompt engineering best practices

### Промпт 5.2: Промпты для AI

```
Создай оптимизированные промпты для каждой задачи AI согласно разделу 3.3.3 ТЗ.

Файл: src/ai/prompts.py

Для каждого промпта:
1. **CLASSIFY_POST_PROMPT** - четкая инструкция по классификации
2. **EXTRACT_DATA_PROMPT** - структурированное извлечение с примерами
3. **GENERATE_DESCRIPTION_PROMPT** - генерация с форматом и стилем

Требования:
- Использовать system/user роли правильно
- Минимизировать токены
- Четкие JSON схемы для ответов
- Few-shot examples где необходимо
- Поддержка русского языка

Используй best practices prompt engineering 2025.
```

---

## Этап 6: Celery Tasks & Queue System

### Промпт 6.1: Celery конфигурация

```
Создай систему очередей задач на Celery + Redis согласно архитектуре ТЗ.

Компоненты:

1. **celery_app.py** - конфигурация Celery:
   - Подключение к Redis
   - Настройка очередей (ai_processing, publishing, sheets_sync)
   - Task routing
   - Retry политики
   - Мониторинг

2. **Tasks**:
   - process_post_task(post_id) - AI обработка поста
   - publish_post_task(post_id) - публикация в канал
   - sync_sheets_data() - синхронизация с Google Sheets
   - update_analytics() - обновление аналитики

3. **Scheduled tasks** (Celery Beat):
   - Синхронизация каналов из Sheets (каждые 60 сек)
   - Обновление аналитики (каждый час)
   - Проверка истекших подписок (каждый день)

Используй Celery best practices, правильную обработку ошибок.
```

**Контекст для Context7:**
- Запроси: Celery latest documentation, Redis integration

---

## Этап 7: Telegram Bot (Bot API)

### Промпт 7.1: Aiogram Bot Structure

```
Создай основную структуру Telegram бота на aiogram 3.x согласно разделу 2.3-2.4 ТЗ.

Компоненты:

1. **bot.py** - точка входа:
   - Инициализация Bot и Dispatcher
   - Регистрация handlers
   - Graceful shutdown

2. **Handlers**:
   - start_handler.py - команда /start, приветствие
   - subscription_handler.py - обработка подписок
   - contacts_handler.py - запросы контактов (callback query)
   - admin_handler.py - админ команды

3. **Middlewares**:
   - UserRegistrationMiddleware - автоматическая регистрация пользователей
   - SubscriptionCheckMiddleware - проверка активной подписки
   - LoggingMiddleware - логирование действий

4. **Keyboards**:
   - inline_keyboards.py - кнопка "Узнать контакты продавца"
   - reply_keyboards.py - основное меню

Используй aiogram 3.x best practices, FSM для сложных диалогов.
```

**Контекст для Context7:**
- Запроси: aiogram 3 latest documentation, middleware patterns

### Промпт 7.2: Publishing Service

```
Создай сервис публикации в новостной канал согласно разделу 2.3 ТЗ.

Класс PublishingService:

1. **format_post(car_data, processed_text)** - форматирование по шаблону:
   - Использовать формат из раздела 2.3.1 ТЗ
   - Эмодзи, структура блоков
   - Inline кнопка "Узнать контакты"

2. **publish_to_channel(post_id)** - публикация:
   - Отправка медиа-группы если несколько фото
   - Отправка текста с кнопкой
   - Сохранение published_message_id в БД
   - Обработка ошибок Telegram API

3. **handle_contact_request(callback_query)** - обработка нажатия кнопки:
   - Проверка подписки пользователя
   - Отправка контактов в ЛС или предложение подписки
   - Логирование запроса в contact_requests

Используй aiogram для отправки, правильную обработку медиа.
```

---

## Этап 8: Система подписок и платежей

### Промпт 8.1: Subscription Manager

```
Создай менеджер подписок согласно разделу 2.4 ТЗ.

Класс SubscriptionManager:

1. **check_subscription(user_id)** - проверка активной подписки:
   - Запрос в БД
   - Проверка end_date
   - Возврат статуса

2. **create_subscription(user_id, subscription_type)** - создание подписки:
   - Расчет end_date (месяц)
   - Создание записи в subscriptions
   - Обновление в Google Sheets

3. **cancel_subscription(user_id)** - отмена подписки:
   - Обновление is_active = False
   - Логирование

4. **check_expired_subscriptions()** - периодическая проверка:
   - Деактивация истекших
   - Уведомление пользователей

Используй async SQLAlchemy, правильную транзакционность.
```

### Промпт 8.2: Payment Integration (заглушка)

```
Создай базовую структуру для интеграции платежей (раздел 2.4.2 помечен как "Позже").

Создай:
1. Интерфейс PaymentProvider с методами:
   - create_invoice()
   - check_payment_status()
   - handle_webhook()

2. Заглушку MockPaymentProvider для тестирования

3. Структуру для будущей интеграции YooKassa и Telegram Stars

Добавь комментарии где будет реальная интеграция.
```

---

## Этап 9: Конфигурация и настройки

### Промпт 9.1: Settings и Environment

```
Создай систему конфигурации проекта.

1. **config.py** с использованием Pydantic Settings:
   - BotConfig (bot_token, channel_id)
   - TelegramSessionConfig (api_id, api_hash, session_file)
   - DatabaseConfig (postgres connection)
   - RedisConfig
   - GoogleSheetsConfig (credentials, spreadsheet_id)
   - OpenAIConfig (api_key, model)
   - AppConfig - общая конфигурация

2. Валидация при загрузке
3. Типизация всех параметров
4. Дефолтные значения где уместно
5. Документация каждой настройки

Используй Pydantic Settings v2, best practices для env management.
```

**Контекст для Context7:**
- Запроси: Pydantic Settings latest documentation

---

## Этап 10: Логирование и мониторинг

### Промпт 10.1: Logging System

```
Создай систему логирования согласно разделу 9.3 ТЗ.

Компоненты:

1. **logging_config.py**:
   - Structured logging (JSON формат)
   - Разные уровни для разных модулей
   - Rotation логов
   - Интеграция с Google Sheets (лист "Логи" для критических событий)

2. **Logger middleware для aiogram и telethon**

3. **Метрики**:
   - Счетчики обработанных постов
   - Ошибки AI
   - Время обработки
   - Статус сессий

Используй structlog или loguru, best practices Python logging.
```

---

## Этап 11: Docker и развертывание

### Промпт 11.1: Docker конфигурация

```
Создай production-ready Docker конфигурацию согласно разделу 9 ТЗ.

Файлы:

1. **Dockerfile** - multi-stage build:
   - Builder stage для зависимостей
   - Runtime stage с минимальным образом
   - Правильные COPY слои для кэширования
   - Non-root user

2. **docker-compose.yml** - все сервисы:
   - bot (aiogram бот)
   - monitor (telethon мониторинг)
   - worker (celery worker)
   - beat (celery beat)
   - postgres (с volume для данных)
   - redis
   - pgadmin (для разработки)

3. **docker-compose.prod.yml** - production overrides:
   - Правильные restart policies
   - Resource limits
   - Health checks
   - Secrets через Docker secrets

4. **Makefile** для удобных команд:
   - make build, make up, make down
   - make migrate, make shell
   - make logs

Используй Docker best practices 2025.
```

### Промпт 11.2: CI/CD и деплой скрипты

```
Создай скрипты для развертывания согласно разделу 9 ТЗ.

1. **deploy.sh** - скрипт деплоя:
   - Проверка переменных окружения
   - Backup БД перед обновлением
   - Pull latest images
   - Применение миграций
   - Перезапуск сервисов
   - Health checks

2. **backup.sh** - резервное копирование:
   - Dump PostgreSQL
   - Backup файла .session
   - Сохранение в безопасное место
   - Rotation старых бэкапов (30 дней)

3. **.github/workflows/test.yml** - базовый CI:
   - Линтинг (ruff, mypy)
   - Тесты (pytest)
   - Build Docker image

Используй shell script best practices, обработка ошибок.
```

---

## Этап 12: Тестирование

### Промпт 12.1: Unit тесты

```
Создай unit тесты для критических компонентов.

Используя pytest, создай тесты для:

1. **test_ai_processor.py**:
   - Моки OpenAI API
   - Тесты классификации
   - Тесты извлечения данных
   - Тесты генерации текста

2. **test_google_sheets.py**:
   - Моки gspread
   - Тесты чтения настроек
   - Тесты записи статистики
   - Тесты кэширования

3. **test_subscription_manager.py**:
   - Тесты проверки подписок
   - Тесты создания/отмены
   - Тесты истечения

4. **test_message_processor.py**:
   - Тесты фильтрации
   - Тесты извлечения контактов
   - Тесты защиты от дублей

Используй pytest fixtures, async test support, покрытие >80%.
```

**Контекст для Context7:**
- Запроси: pytest latest, pytest-asyncio

---

## Этап 13: Документация

### Промпт 13.1: Документация проекта

```
Создай полную документацию проекта.

Файлы:

1. **README.md** - обзор и quick start:
   - Описание проекта
   - Требования
   - Быстрый старт
   - Основные команды

2. **docs/SETUP.md** - детальная настройка:
   - Создание Telegram Bot
   - Настройка User Session (раздел 5 ТЗ)
   - Настройка Google Sheets (раздел 6 ТЗ)
   - Переменные окружения

3. **docs/ARCHITECTURE.md** - архитектура:
   - Диаграмма компонентов
   - Flow диаграммы (разделы 4.1-4.3 ТЗ)
   - Описание модулей

4. **docs/API.md** - внутренние API:
   - Описание основных классов
   - Примеры использования

5. **docs/DEPLOYMENT.md** - деплой и поддержка:
   - Инструкции по развертыванию
   - Мониторинг и логи
   - Troubleshooting

Используй Markdown, диаграммы Mermaid.
```

---

## Порядок выполнения промптов

### Фаза 1: Фундамент (Промпты 1.1 → 2.1 → 2.2)
Результат: структура проекта, БД модели, миграции

### Фаза 2: Интеграции (Промпты 3.1 → 3.2 → 4.1 → 4.2)
Результат: Google Sheets, Telegram мониторинг

### Фаза 3: Обработка (Промпты 5.1 → 5.2 → 6.1)
Результат: AI обработка, очереди задач

### Фаза 4: Bot & Publishing (Промпты 7.1 → 7.2 → 8.1 → 8.2)
Результат: бот, публикация, подписки

### Фаза 5: Инфраструктура (Промпты 9.1 → 10.1 → 11.1 → 11.2)
Результат: конфиг, логи, Docker, деплой

### Фаза 6: QA & Docs (Промпты 12.1 → 13.1)
Результат: тесты, документация

---

## Рекомендации по работе с промптами

### 1. Context7 запросы перед каждой фазой:
```
- Фаза 1: sqlalchemy, alembic
- Фаза 2: gspread, telethon
- Фаза 3: openai, celery
- Фаза 4: aiogram
- Фаза 5: pydantic-settings
- Фаза 6: pytest
```

### 2. Проверка после каждого промпта:
- Запустить линтер (ruff)
- Проверить типы (mypy)
- Убедиться в работоспособности

### 3. Итеративная доработка:
Если результат не идеален, используй уточняющие промпты:
```
"Оптимизируй код из предыдущего промпта:
- Добавь обработку ошибок
- Улучши типизацию
- Добавь docstrings
- Следуй принципам SOLID"
```

### 4. Не делай все сразу:
- Выполняй по 2-3 промпта за раз
- Тестируй результат
- Переходи к следующей фазе только после проверки

---

## Дополнительные промпты для доработки

### Промпт: Оптимизация производительности
```
Проанализируй текущий код проекта и оптимизируй:
1. SQL запросы (добавь нужные индексы)
2. Кэширование частых операций
3. Batch-операции для Google Sheets
4. Connection pooling для БД
5. Async/await оптимизация

Используй профилирование и best practices.
```

### Промпт: Безопасность
```
Проведи аудит безопасности проекта:
1. Валидация всех входящих данных
2. SQL injection защита
3. Безопасное хранение секретов
4. Rate limiting для всех API
5. Защита от SSRF атак

Используй OWASP best practices.
```

### Промпт: Мониторинг
```
Добавь систему мониторинга:
1. Health check endpoints
2. Prometheus метрики
3. Grafana дашборды
4. Алерты при ошибках
5. Мониторинг статуса Telegram Session

Используй современные инструменты мониторинга.
```

---

**Итого: 21 основной промпт + 3 дополнительных**

Каждый промпт сфокусирован на конкретной задаче и не перегружает контекст AI агента.


